# Python topic modeling using bigartm library

## Общее описание

Набор скриптов из этой папки позволяет находить близкие документы на английском из обучающий выборки к некоторому документу на английском языке.


## Данные для обучения своей модели

По [ссылке](https://drive.google.com/drive/folders/0B5Sz52EAqYyTOG5zVkhxOVdCc2s?usp=sharing) доступны предобработанные данные.

В preprocessed_files.tar.gz лежат txt файлы с авторами, названиями, кодами журналов, спонсорами, темами, абстрактами, текстами статей.
В txt n-ой строке в каждом файле соответсвует одна и та же статья.

В no_spec_topic_articles.csv и plos_med_articles.csv часть колонок из одноименных файлов, но в формате который можно прочитать не только из R. Например он хорошо считывается pandas (см preprocess.ipynb).


## Подготовка к запуска примера

Для запуска примера поиска близких статей требуется:
* установить python2
* установить пакеты: nltk, gensim, numpy, pandas, scipy
* [скачать](https://drive.google.com/drive/folders/0B5Sz52EAqYyTczdKSTd4Uy03WlE) компоненты модели и положить их в папку с некоторым путем path_1 до неё
* скачать готовые примеры статей или взять свои и положить в папку с некоторым путем path_2. Файлы статей должны быть организованы построчно следующим образом:
   * название статьи на первой строке
   * авторы. Требуется заменить пробелы между ФИО на символ `_`
   * абстракт статьи одной длиной строкой
   * основной текст статьи одной длиной строкой
   * код журнала. Мало влияет на результат, указывать не требуется.

Часть значений может быть пропущено. Для это достаточно оставить пустую строку.
Предобрабатывать файлы для поиска близких к ним отдельно не нужно, так как существует встроенный препроцессор документов.


## Запуск примера

Пример запуска:
`python2 find_nearby.py --model_store_path=path_1 -docs_store_path=path_2`

Параметры для запуска для удобства могут переданы через файл args.txt. Если передан хотя бы один параметр через cmd, то параметры из файла не считыватся.




